{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Equipo\n",
        "---\n",
        "Gamaliel Marines Olvera\n",
        "A01708746\n",
        "\n",
        "Uri Jared Gopar Morales\n",
        "A01709413\n",
        "\n",
        "José Antonio Miranda Baños\n",
        "A01611795\n",
        "\n",
        "María Fernanda Moreno Gómez\n",
        "A01708653\n",
        "\n",
        "Oskar Adolfo Villa López\n",
        "A01275287\n",
        "\n",
        "Luis Ángel Cruz García\n",
        "A01736345\n",
        "\n"
      ],
      "metadata": {
        "id": "Qkxc6nXzsH4w"
      },
      "id": "Qkxc6nXzsH4w"
    },
    {
      "cell_type": "markdown",
      "id": "41b7905f-a070-4ffe-abfc-67fbcd2adaa9",
      "metadata": {
        "id": "41b7905f-a070-4ffe-abfc-67fbcd2adaa9"
      },
      "source": [
        "####Activity 3: Implementing a Translator\n",
        "\n",
        "- Objective\n",
        "\n",
        "To understand the Transformer Architecture by Implementing a translator.\n",
        "\n",
        "- Instructions\n",
        "\n",
        "    This activity requires submission in teams. While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
        "\n",
        "    Follow the provided code. The code already implements a transformer from scratch as explained in one of [week's 9 videos](https://youtu.be/XefFj4rLHgU)\n",
        "\n",
        "    Since the provided code already implements a simple translator, your job for this assignment is to understand it fully, and document it using pictures, figures, and markdown cells.  You should test your translator with at least 10 sentences. The dataset used for this task was obtained from [Tatoeba, a large dataset of sentences and translations](https://tatoeba.org/en/downloads).\n",
        "  \n",
        "- Evaluation Criteria\n",
        "\n",
        "    - Code Readability and Comments\n",
        "    - Traning a translator\n",
        "    - Translating at least 10 sentences.\n",
        "\n",
        "- Submission\n",
        "\n",
        "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Environment**"
      ],
      "metadata": {
        "id": "rR9j88UHRCJF"
      },
      "id": "rR9j88UHRCJF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Libraries**"
      ],
      "metadata": {
        "id": "jCIbohwJURxQ"
      },
      "id": "jCIbohwJURxQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries\n",
        "\n",
        "To build a translator using transformers, we first import essential libraries that will help with data manipulation, mathematical operations, model construction, and utilities.\n",
        "\n",
        "#### Data Manipulation\n",
        "- `pandas` (`import pandas as pd`): Used for handling and processing datasets efficiently.\n",
        "\n",
        "#### Mathematical Operations\n",
        "- `math`: Provides access to various mathematical functions and constants.\n",
        "- `numpy` (`import numpy as np`): A core library for numerical computations and handling arrays, which is useful for manipulating data before feeding it into our model.\n",
        "\n",
        "#### PyTorch (Deep Learning Framework)\n",
        "- `torch` (`import torch`): The core PyTorch library for creating and manipulating tensors, which are fundamental data structures in deep learning.\n",
        "- `torch.nn` (`import torch.nn as nn`): A module that provides classes and functions to build neural networks.\n",
        "- `torch.nn.functional` (`import torch.nn.functional as F`): Contains functions for various neural network layers and operations, like activation functions, which are commonly used in model definitions.\n",
        "- `torch.optim` (`import torch.optim as optim`): Optimizers for training neural networks, allowing for different strategies to adjust model parameters.\n",
        "- `torch.utils.data` (`from torch.utils.data import Dataset, DataLoader`):\n",
        "  - `Dataset`: Used to define and organize the dataset for training.\n",
        "  - `DataLoader`: Allows us to load data in batches, making training more efficient and manageable.\n",
        "\n",
        "#### Utilities\n",
        "- `collections.Counter` (`from collections import Counter`): A subclass for counting hashable objects, helping in tasks like word frequency counting.\n",
        "- `re` (`import re`): Provides regular expression support for efficient text processing and cleaning.\n",
        "\n",
        "Together, these libraries provide the tools necessary for data preparation, model building, and training in a neural translation model.\n"
      ],
      "metadata": {
        "id": "bT7aCTpFgH2v"
      },
      "id": "bT7aCTpFgH2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f240f0d8-d9e0-4632-962f-1a5a7881cb5f",
      "metadata": {
        "id": "f240f0d8-d9e0-4632-962f-1a5a7881cb5f"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "\n",
        "# Data Manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Mathematical Operations\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch (Deep Learning Framework)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Utilities\n",
        "from collections import Counter\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Drive**"
      ],
      "metadata": {
        "id": "lyBf4xCuUXFV"
      },
      "id": "lyBf4xCuUXFV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebcf8f0-fcf0-4cf7-a549-0c68aa8eab1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ebcf8f0-fcf0-4cf7-a549-0c68aa8eab1a",
        "outputId": "ef7252e4-7ca7-4d8a-d1fc-9cd265c92037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google Drive in Google Colab.\n",
        "# Access to files and directories stored in Google Drive from a Colab notebook.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Device**"
      ],
      "metadata": {
        "id": "lfX8GEScUlYz"
      },
      "id": "lfX8GEScUlYz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting the Device for Computation\n",
        "\n",
        "To ensure that the code leverages available hardware resources efficiently, we set up a device for running computations:\n",
        "\n",
        "- `torch.device('cuda' if torch.cuda.is_available() else 'cpu')`:\n",
        "  - This line checks if a CUDA-enabled GPU is available on the system.\n",
        "  - If a GPU is available, it sets the device to `'cuda'`, allowing for faster computations as GPUs handle parallel operations efficiently.\n",
        "  - If no GPU is detected, it defaults to `'cpu'`, where computations will still run but might be slower than on a GPU.\n",
        "\n",
        "- `print(device)`:\n",
        "  - This line prints the selected device, showing either `'cuda'` for GPU or `'cpu'` for CPU. This confirmation helps you verify that the code is using the expected hardware.\n",
        "\n",
        "By dynamically setting the device, we ensure that the model will run on the most powerful hardware available, optimizing training and inference performance.\n"
      ],
      "metadata": {
        "id": "lmXilaa7gPS1"
      },
      "id": "lmXilaa7gPS1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a CUDA-enabled GPU is available; if so, set the device to GPU, otherwise use CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w14PHwCT_uy",
        "outputId": "cd522fa5-d9b5-40d5-c76e-16597b6b98af"
      },
      "id": "4w14PHwCT_uy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Loading**"
      ],
      "metadata": {
        "id": "4CZvf5xoQT0h"
      },
      "id": "4CZvf5xoQT0h"
    },
    {
      "cell_type": "markdown",
      "id": "17f54c65",
      "metadata": {
        "heading_collapsed": true,
        "id": "17f54c65"
      },
      "source": [
        "###**Load Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Dataset\n",
        "\n",
        "To build a translation model, we start by loading a Spanish-English dataset, which will be used to train the model.\n",
        "\n",
        "- `PATH = '/content/drive/MyDrive/Deep_Learning_Team/eng-spa2024.csv'`:\n",
        "  - Specifies the file path for the Spanish-English dataset stored in Google Drive.\n",
        "  - This path points to the location where the dataset is saved, making it accessible for loading.\n",
        "\n",
        "- `df = pd.read_csv(PATH, encoding='latin1', header=None)`:\n",
        "  - Loads the dataset into a pandas DataFrame for easier handling and manipulation.\n",
        "  - `encoding='latin1'`: Specifies the encoding to ensure correct handling of special characters common in Spanish.\n",
        "  - `header=None`: Indicates that the file does not contain a header row, so columns will be assigned default numerical labels.\n",
        "  \n",
        "This dataset will provide the Spanish-English text pairs necessary for training the translation model.\n"
      ],
      "metadata": {
        "id": "MbsFNhSTgZEJ"
      },
      "id": "MbsFNhSTgZEJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f02c0c2",
      "metadata": {
        "hidden": true,
        "collapsed": true,
        "id": "8f02c0c2"
      },
      "outputs": [],
      "source": [
        "# Define file path for the Spanish-English dataset.\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/eng-spa2024.csv'\n",
        "\n",
        "# Load dataset into a DataFrame using tab ('\\t') as the separator.\n",
        "df = pd.read_csv(PATH, encoding='latin1', header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**CVS File to TXT File**"
      ],
      "metadata": {
        "id": "O_IjeO2xU6_p"
      },
      "id": "O_IjeO2xU6_p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the Dataset\n",
        "\n",
        "After loading the dataset, we perform several preprocessing steps to prepare it for model training.\n",
        "\n",
        "- **Select Relevant Columns**:\n",
        "  - `eng_spa_cols = df.iloc[:, [1, 3]]`: Selects only the columns containing English and Spanish text.\n",
        "  - The columns are chosen by their positions: `1` (English text) and `3` (Spanish text), simplifying the dataset to the text pairs we need.\n",
        "\n",
        "- **Calculate and Sort by Text Length**:\n",
        "  - `eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()`: Calculates the character length of each entry in the English column and stores it in a new column called `length`. This length information will help us sort the dataset.\n",
        "  - `eng_spa_cols = eng_spa_cols.sort_values(by='length')`: Sorts the DataFrame based on the `length` column, arranging text pairs in ascending order of English text length. Sorting by length can improve the training efficiency, as shorter sequences are processed first.\n",
        "\n",
        "- **Clean Up the DataFrame**:\n",
        "  - `eng_spa_cols = eng_spa_cols.drop(columns=['length'])`: Removes the `length` column after sorting, as it's no longer needed for training.\n",
        "\n",
        "- **Save the Processed Data**:\n",
        "  - `output_file_path = '/content/drive/MyDrive/Deep_Learning_Team/eng-spa2024.txt'`: Specifies the output file path where the cleaned dataset will be saved.\n",
        "  - `eng_spa_cols.to_csv(output_file_path, sep='\\t', index=False, header=False)`: Saves the processed DataFrame to a new text file using tab (`'\\t'`) as the separator, without including the index or header.\n",
        "\n",
        "By selecting only the necessary columns, sorting by text length, and saving the cleaned data, we create a more manageable and optimized dataset for training the translation model.\n"
      ],
      "metadata": {
        "id": "CpDwXmsWgjda"
      },
      "id": "CpDwXmsWgjda"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the relevant columns for English and Spanish from the DataFrame.\n",
        "eng_spa_cols = df.iloc[:, [1, 3]]\n",
        "\n",
        "# Calculate the length of each entry in the first column (English text) and store it as a new column.\n",
        "eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n",
        "\n",
        "# Sort the DataFrame based on the 'length' column to order entries by the length of the English text.\n",
        "eng_spa_cols = eng_spa_cols.sort_values(by='length')\n",
        "\n",
        "# Remove the 'length' column after sorting, as it is no longer needed.\n",
        "eng_spa_cols = eng_spa_cols.drop(columns=['length'])\n",
        "\n",
        "# Define output file path and save the processed DataFrame to a new file without index or header.\n",
        "output_file_path = '/content/drive/MyDrive/Colab Notebooks/eng-spa2024.csv'\n",
        "eng_spa_cols.to_csv(output_file_path, sep='\\t', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2exafyPtSv-U",
        "outputId": "460916a6-4df2-4a0f-e9cf-3fc12e76070f"
      },
      "id": "2exafyPtSv-U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-9e1bb1397554>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d468e9a",
      "metadata": {
        "id": "7d468e9a"
      },
      "source": [
        "##**Transformer - Attention Is All You Need**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Up Transformer Parameters\n",
        "\n",
        "To ensure consistent training results and manage input data effectively, we define a random seed and a maximum sequence length.\n",
        "\n",
        "- **Random Seed for Reproducibility**:\n",
        "  - `torch.manual_seed(23)`: Sets a fixed random seed for PyTorch operations. Using a seed makes model training deterministic, meaning the results will be consistent every time the code is run. This is essential for debugging and comparing different model configurations.\n",
        "\n",
        "- **Maximum Sequence Length**:\n",
        "  - `MAX_SEQ_LEN = 128`: Sets the maximum sequence length for the input data. This limits the number of tokens that the model will process per input sequence.\n",
        "  - Limiting sequence length helps control memory usage and computation time, as longer sequences require more resources. Setting an appropriate length ensures that the model can handle most sentences without exceeding resource limits.\n",
        "\n",
        "These initial configurations help create a stable and manageable setup for building a transformer-based translation model.\n"
      ],
      "metadata": {
        "id": "Sgu0NUklgqju"
      },
      "id": "Sgu0NUklgqju"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a random seed for reproducibility in PyTorch operations.\n",
        "torch.manual_seed(23)\n",
        "\n",
        "# Define the maximum sequence length for input data, setting a limit for processing.\n",
        "MAX_SEQ_LEN = 128"
      ],
      "metadata": {
        "id": "CjCcnFOeUOr_"
      },
      "id": "CjCcnFOeUOr_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Positional Embedding**"
      ],
      "metadata": {
        "id": "qVxtzHObXS3C"
      },
      "id": "qVxtzHObXS3C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The positional embedding layer encodes positional information into the embeddings of tokens, allowing the transformer model to understand the order of tokens in a sequence, as it lacks inherent sequence information.\n",
        "\n",
        "Key Components of the PositionalEmbedding Class\n",
        "- **Positional Encoding Matrix**: A matrix is created to store position encodings for each position in the sequence. These encodings use a combination of sine and cosine functions, ensuring that each position has a unique pattern of values. This helps the model distinguish between different token positions in a consistent way.\n",
        "- **Encoding Formula**: The encoding values are based on the sine and cosine functions, with different frequencies for even and odd dimensions. This formulation ensures that the embeddings reflect relative position information.\n",
        "- **Integration with Input Embeddings**: In the forward pass, these positional encodings are added directly to the token embeddings, enhancing them with position-related information.\n",
        "\n",
        "This layer allows the transformer to incorporate sequence order information, which is essential for tasks like translation where word order influences meaning.\n",
        "\n"
      ],
      "metadata": {
        "id": "6btLqpD1g2iB"
      },
      "id": "6btLqpD1g2iB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a positional embedding layer for adding position information to token embeddings.\n",
        "class PositionalEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_seq_len=MAX_SEQ_LEN):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Create a matrix to store positional encodings for each token position.\n",
        "        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model, device=device)\n",
        "\n",
        "        # Calculate sine and cosine position encodings.\n",
        "        token_pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n",
        "        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n",
        "\n",
        "        # Add a batch dimension and adjust shape for compatibility.\n",
        "        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return x + self.pos_embed_matrix[:x.size(0), :]"
      ],
      "metadata": {
        "id": "suie3V1BXYXS"
      },
      "id": "suie3V1BXYXS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Multi Head Attention**"
      ],
      "metadata": {
        "id": "5rNPaVILXccZ"
      },
      "id": "5rNPaVILXccZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multi-head attention mechanism enables the model to attend to different parts of a sequence simultaneously, which is critical for capturing various aspects of linguistic relationships in translation tasks. In this class, we implement a multi-head attention layer to split the attention into multiple \"heads\" and capture different representation subspaces.\n",
        "\n",
        "#### Key Components of the MultiHeadAttention Class\n",
        "- **Initialization**: The model dimension (`d_model`) and number of heads (`num_heads`) are specified. The embedding dimension is divided by the number of heads, allowing each head to focus on a different part of the input sequence in parallel.\n",
        "- **Linear Projections for Q, K, V**: The input is projected into Query (Q), Key (K), and Value (V) matrices through linear layers. This separation allows the model to determine \"what to attend to\" in the input sequence for each head.\n",
        "- **Scale Dot-Product Attention**: The dot-product attention is computed, scaled for numerical stability, and then passed through a softmax function to create attention scores, determining the importance of each token in the sequence.\n",
        "- **Output Projection**: The outputs from all attention heads are concatenated and linearly projected to match the original model dimension, integrating the multi-head attention information.\n",
        "\n",
        "This multi-head attention layer captures multiple aspects of context in the sequence, enhancing the model’s understanding of complex relationships in language and helping it handle tasks like translation effectively.\n"
      ],
      "metadata": {
        "id": "_UC8JKUVhRQn"
      },
      "id": "_UC8JKUVhRQn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a multi-head attention layer for capturing various representation subspaces.\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model=512, num_heads=8):\n",
        "\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, 'Embedding size must be divisible by number of heads'\n",
        "\n",
        "        # Define dimensions for each attention head.\n",
        "        self.d_v = d_model // num_heads\n",
        "        self.d_k = self.d_v\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Linear layers for projecting inputs into Q, K, V spaces.\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "\n",
        "        batch_size = Q.size(0)\n",
        "\n",
        "        # Q, K, V -> [batch_size, seq_len, num_heads*d_k] after transpose Q, K, V -> [batch_size, num_heads, seq_len, d_k]\n",
        "\n",
        "        # Project and reshape Q, K, V to enable multi-head attention.\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Calculate attention output.\n",
        "        weighted_values, attention = self.scale_dot_product(Q, K, V, mask)\n",
        "\n",
        "        # Reshape the output back to original dimensions.\n",
        "        weighted_values = weighted_values.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
        "        weighted_values = self.W_o(weighted_values)\n",
        "\n",
        "        return weighted_values, attention\n",
        "\n",
        "    def scale_dot_product(self, Q, K, V, mask=None):\n",
        "\n",
        "        # Compute attention scores and apply mask if provided.\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention = F.softmax(scores, dim=-1)\n",
        "\n",
        "        # Calculate weighted sum of values.\n",
        "        weighted_values = torch.matmul(attention, V)\n",
        "\n",
        "        return weighted_values, attention"
      ],
      "metadata": {
        "id": "Lfeh4s25Xh8u"
      },
      "id": "Lfeh4s25Xh8u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Position Feed Forward**"
      ],
      "metadata": {
        "id": "y29ugHiGYXup"
      },
      "id": "y29ugHiGYXup"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The position feedforward layer is a component within the Transformer architecture that applies a fully connected neural network to each position independently. This layer helps the model capture complex relationships by transforming each position's embedding through a multi-layer perceptron (MLP).\n",
        "\n",
        "Key Components of the PositionFeedForward Class\n",
        "- **Two Linear Transformations**: The feedforward layer consists of two linear (fully connected) layers. The first transforms the embedding dimension (`d_model`) to a larger intermediate dimension (`d_ff`), while the second reduces it back to the original model dimension.\n",
        "- **ReLU Activation**: A ReLU activation function is applied between the two linear layers, introducing non-linearity to help the model capture more complex patterns.\n",
        "\n",
        "This feedforward layer is applied to each position separately, allowing the model to learn and refine the representation of each token independently of the others. It’s a crucial component for increasing the model’s capacity to learn diverse features in the sequence."
      ],
      "metadata": {
        "id": "8IYluu45h0IF"
      },
      "id": "8IYluu45h0IF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a feedforward neural network layer used within the Transformer.\n",
        "class PositionFeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, d_ff):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Two linear layers for the feedforward network.\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Apply ReLU activation between two linear transformations.\n",
        "        return self.linear2(F.relu(self.linear1(x)))"
      ],
      "metadata": {
        "id": "7IVY19dvYa7P"
      },
      "id": "7IVY19dvYa7P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Encoder Sub Layer**"
      ],
      "metadata": {
        "id": "HAcDr_ltYh-9"
      },
      "id": "HAcDr_ltYh-9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The EncoderSubLayer class defines a core component of the Transformer encoder, combining self-attention and feedforward layers with normalization and residual connections. Each sublayer enhances the model's ability to capture relationships in the input sequence.\n",
        "\n",
        "Key Components of the EncoderSubLayer Class\n",
        "- **Self-Attention and Feedforward Layers**:\n",
        "  - The self-attention layer enables the model to focus on different parts of the input sequence, capturing contextual relationships.\n",
        "  - The feedforward layer refines the representation of each token independently, adding complexity to the model's understanding of each position.\n",
        "\n",
        "- **Normalization and Dropout**:\n",
        "  - Layer normalization stabilizes and accelerates training by maintaining consistent input distributions.\n",
        "  - Dropout provides regularization, helping prevent overfitting by randomly zeroing out portions of the input.\n",
        "\n",
        "- **Residual Connections**:\n",
        "  - Residual (or skip) connections allow the original input to bypass each layer, ensuring that information flows through the network and making training more stable.\n",
        "\n",
        "This sublayer forms the building block of the Transformer encoder, stacking multiple instances to create deeper and more expressive models for tasks like translation."
      ],
      "metadata": {
        "id": "w2LztGFKh_do"
      },
      "id": "w2LztGFKh_do"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sublayer within the encoder, which includes attention and feedforward layers.\n",
        "class EncoderSubLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Self-attention and feedforward layers.\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = PositionFeedForward(d_model, d_ff)\n",
        "\n",
        "        # Normalization and dropout layers.\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        # Apply self-attention, normalization, and residual connections.\n",
        "        attention_score, _ = self.self_attn(x, x, x, mask)\n",
        "        x = x + self.dropout1(attention_score)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Apply feedforward, normalization, and residual connections.\n",
        "        x = x + self.dropout2(self.ffn(x))\n",
        "\n",
        "        return self.norm2(x)"
      ],
      "metadata": {
        "id": "lRkPFe34YoFF"
      },
      "id": "lRkPFe34YoFF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Encoder**"
      ],
      "metadata": {
        "id": "ft4lz8__YtXC"
      },
      "id": "ft4lz8__YtXC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Encoder class implements the Transformer encoder, which consists of multiple stacked layers to learn complex representations of the input sequence. This stack of layers allows the model to progressively refine its understanding of the sequence.\n",
        "\n",
        "Key Components of the Encoder Class\n",
        "- **Stacked Encoder Sublayers**:\n",
        "  - The encoder is composed of multiple `EncoderSubLayer` instances, where each sublayer includes self-attention and feedforward components with normalization and residual connections.\n",
        "  - Stacking several sublayers helps the model capture increasingly abstract patterns and relationships across the input.\n",
        "\n",
        "- **Layer Normalization**:\n",
        "  - After the input passes through all encoder layers, a final layer normalization step is applied to stabilize the output. This helps maintain consistent representation quality across the entire model.\n",
        "\n",
        "Forward Pass\n",
        "- The input sequence passes sequentially through each encoder layer, where each layer processes and refines the input. This approach allows the encoder to build a rich and hierarchical representation of the sequence, essential for downstream tasks like translation.\n",
        "\n",
        "The encoder structure forms a powerful sequence processor, enabling the model to learn deep, contextual representations that enhance its understanding of the input text."
      ],
      "metadata": {
        "id": "23gIIG2IiNhO"
      },
      "id": "23gIIG2IiNhO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder consisting of multiple sublayers for representation learning.\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Stack multiple encoder sublayers.\n",
        "        self.layers = nn.ModuleList([EncoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        # Pass the input through each encoder layer.\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "jPZDiKmfYscH"
      },
      "id": "jPZDiKmfYscH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Decoder Sub Layer**"
      ],
      "metadata": {
        "id": "597R0iPFYzN3"
      },
      "id": "597R0iPFYzN3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DecoderSubLayer class implements a sublayer within the Transformer decoder, combining self-attention, cross-attention, and feedforward layers. This layer enables the decoder to focus on both the target sequence and the encoder's output, allowing it to generate meaningful output sequences.\n",
        "\n",
        "Key Components of the DecoderSubLayer Class\n",
        "- **Self-Attention Layer**:\n",
        "  - This layer focuses on the target sequence itself, enabling the model to learn dependencies within the generated sequence. A target mask is applied to prevent the model from attending to future tokens.\n",
        "\n",
        "- **Cross-Attention Layer**:\n",
        "  - The cross-attention layer attends to the encoder's output, allowing the decoder to align with relevant parts of the input sequence. This enables the model to use information from the input sequence when generating each token in the target sequence.\n",
        "\n",
        "- **Feedforward Network**:\n",
        "  - A feedforward layer further refines the representation at each position, adding complexity to the model's understanding of each token in context.\n",
        "\n",
        "- **Normalization and Dropout**:\n",
        "  - Layer normalization and dropout are applied after each main component to stabilize training and prevent overfitting. Residual connections are also included to maintain a steady flow of information through the model.\n",
        "\n",
        "Forward Pass\n",
        "- The target sequence is passed through self-attention, cross-attention, and feedforward layers sequentially, with residual connections, dropout, and normalization applied throughout.\n",
        "\n",
        "This sublayer is crucial for the decoder’s ability to generate contextually relevant output by dynamically focusing on both the generated sequence and the encoded input."
      ],
      "metadata": {
        "id": "wLjHVLahRrCC"
      },
      "id": "wLjHVLahRrCC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sublayer within the decoder, incorporating self-attention, cross-attention, and feedforward layers.\n",
        "class DecoderSubLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Self-attention, cross-attention, and feedforward layers.\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionFeedForward(d_model, d_ff)\n",
        "\n",
        "        # Normalization and dropout layers.\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, target_mask=None, encoder_mask=None):\n",
        "\n",
        "        # Self-attention with target mask.\n",
        "        attention_score, _ = self.self_attn(x, x, x, target_mask)\n",
        "        x = x + self.dropout1(attention_score)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Cross-attention with encoder output and mask.\n",
        "        encoder_attn, _ = self.cross_attn(x, encoder_output, encoder_output, encoder_mask)\n",
        "        x = x + self.dropout2(encoder_attn)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        # Feedforward network with residual and normalization.\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + self.dropout3(ff_output)\n",
        "\n",
        "        return self.norm3(x)"
      ],
      "metadata": {
        "id": "yi4GwFclY2vV"
      },
      "id": "yi4GwFclY2vV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Decoder**"
      ],
      "metadata": {
        "id": "7YgsXYDrY7Lk"
      },
      "id": "7YgsXYDrY7Lk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decoder class defines the Transformer decoder, which consists of multiple stacked sublayers designed to generate a target sequence based on the encoder’s output. The decoder progressively refines its understanding of the input and target sequence, enabling accurate and contextually relevant sequence generation.\n",
        "\n",
        "Key Components of the Decoder Class\n",
        "- **Stacked Decoder Sublayers**:\n",
        "  - The decoder is composed of several `DecoderSubLayer` instances, each of which includes self-attention, cross-attention, and feedforward layers.\n",
        "  - Stacking these sublayers allows the model to progressively build a rich representation of the target sequence, incorporating both self-attended target context and cross-attended input context.\n",
        "\n",
        "- **Layer Normalization**:\n",
        "  - After passing through all sublayers, a final layer normalization is applied to stabilize the output representation. This ensures consistency across the model and improves overall training stability.\n",
        "\n",
        "Forward Pass\n",
        "- The target sequence is passed through each decoder layer, with each layer adding information by attending to the target sequence itself and to the encoder’s output. This approach enables the model to capture nuanced relationships within the target and between the target and input sequences.\n",
        "\n",
        "The decoder structure forms the backbone of the Transformer’s generation capabilities, allowing it to produce accurate translations or other sequence-to-sequence outputs."
      ],
      "metadata": {
        "id": "xOYevPvrR1R7"
      },
      "id": "xOYevPvrR1R7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the decoder consisting of multiple sublayers for sequence generation.\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Stack multiple decoder sublayers.\n",
        "        self.layers = nn.ModuleList([DecoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, encoder_output, target_mask, encoder_mask):\n",
        "\n",
        "        # Pass the input through each decoder layer.\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, target_mask, encoder_mask)\n",
        "\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "q2NDcnXqXAiA"
      },
      "id": "q2NDcnXqXAiA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Transformer**"
      ],
      "metadata": {
        "id": "jLcBqMrJbE4h"
      },
      "id": "jLcBqMrJbE4h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Transformer class implements an encoder-decoder structure for sequence-to-sequence tasks, like language translation. This model uses attention mechanisms and positional encodings to capture complex relationships in the input and output sequences.\n",
        "\n",
        "Key Components of the Transformer Class\n",
        "- **Embedding Layers**:\n",
        "  - Separate embedding layers for the source and target vocabulary map tokens to continuous vector representations of a specified dimension (`d_model`).\n",
        "  - Positional encoding is added to these embeddings, helping the model understand token order within sequences.\n",
        "\n",
        "- **Encoder and Decoder**:\n",
        "  - The encoder processes the input sequence, learning a rich representation of it.\n",
        "  - The decoder, leveraging both the target sequence (for self-attention) and encoder’s output (for cross-attention), generates the target sequence progressively.\n",
        "\n",
        "- **Output Layer**:\n",
        "  - A final linear layer maps the decoder’s output to the target vocabulary, producing logits for each token in the target sequence.\n",
        "\n",
        "Forward Pass\n",
        "1. **Generate Masks**: Masks are created for both the source and target sequences to prevent attending to padding tokens and future tokens in the target sequence.\n",
        "2. **Encoding**: The source sequence is embedded, positionally encoded, and passed through the encoder to produce the encoder’s output.\n",
        "3. **Decoding**: The target sequence is embedded, positionally encoded, and passed through the decoder, which also attends to the encoder’s output.\n",
        "4. **Output Mapping**: The decoder’s output is mapped to the target vocabulary, producing a probability distribution over possible next tokens.\n",
        "\n",
        "This architecture forms the basis of a powerful Transformer model capable of handling a wide range of sequence generation tasks by effectively encoding and decoding input and output sequences."
      ],
      "metadata": {
        "id": "y5lrUKEySDnx"
      },
      "id": "y5lrUKEySDnx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61070162",
      "metadata": {
        "code_folding": [],
        "id": "61070162"
      },
      "outputs": [],
      "source": [
        "# Define a Transformer model with encoder-decoder structure.\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, input_vocab_size, target_vocab_size, max_len=MAX_SEQ_LEN, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Define embedding layers for input and target vocabulary.\n",
        "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "\n",
        "        # Positional embedding to encode token positions.\n",
        "        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n",
        "\n",
        "        # Define encoder and decoder modules.\n",
        "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
        "        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
        "\n",
        "        # Output layer to map decoder output to vocabulary space.\n",
        "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
        "\n",
        "    def forward(self, source, target):\n",
        "\n",
        "        # Generate masks for encoder and decoder inputs.\n",
        "        source_mask, target_mask = self.mask(source, target)\n",
        "\n",
        "        # Apply embedding and positional encoding to source input.\n",
        "        source = self.encoder_embedding(source) * math.sqrt(self.encoder_embedding.embedding_dim)\n",
        "        source = self.pos_embedding(source)\n",
        "\n",
        "        # Pass through encoder.\n",
        "        encoder_output = self.encoder(source, source_mask)\n",
        "\n",
        "        # Apply embedding and positional encoding to target input.\n",
        "        target = self.decoder_embedding(target) * math.sqrt(self.decoder_embedding.embedding_dim)\n",
        "        target = self.pos_embedding(target)\n",
        "\n",
        "        # Pass through decoder.\n",
        "        output = self.decoder(target, encoder_output, target_mask, source_mask)\n",
        "\n",
        "        # Map decoder output to target vocabulary size.\n",
        "        return self.output_layer(output)\n",
        "\n",
        "    def mask(self, source, target):\n",
        "\n",
        "        # Create source mask (1 for non-padding tokens, 0 for padding).\n",
        "        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Create target mask (1 for non-padding tokens, 0 for padding).\n",
        "        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Generate triangular mask to prevent attending to future tokens.\n",
        "        size = target.size(1)\n",
        "        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n",
        "        target_mask = target_mask & no_mask\n",
        "\n",
        "        return source_mask, target_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da6b2d4",
      "metadata": {
        "heading_collapsed": true,
        "id": "6da6b2d4"
      },
      "source": [
        "##**Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Transformer Model\n",
        "\n",
        "To test the Transformer model, we define key parameters for the sequence length, batch size, and vocabulary size, and then generate random input data for the source and target sequences.\n",
        "\n",
        "Parameters\n",
        "- **seq_len_source**: Specifies the length of each source sequence (e.g., 10 tokens per sequence).\n",
        "- **seq_len_target**: Specifies the length of each target sequence (e.g., 10 tokens per sequence).\n",
        "- **batch_size**: Defines the number of samples in each batch (e.g., 2 sequences per batch).\n",
        "- **input_vocab_size**: Sets the vocabulary size for the source language (e.g., 50 unique tokens).\n",
        "- **target_vocab_size**: Sets the vocabulary size for the target language (e.g., 50 unique tokens).\n",
        "\n",
        "Generating Input Data\n",
        "- **source**: A random tensor simulating a batch of source sequences, where each token is randomly selected from the source vocabulary.\n",
        "- **target**: A random tensor simulating a batch of target sequences, where each token is randomly selected from the target vocabulary.\n",
        "\n",
        "These randomly generated sequences allow us to verify the Transformer model's forward pass and assess whether the model is functioning as expected without training."
      ],
      "metadata": {
        "id": "AXke4O96TB4K"
      },
      "id": "AXke4O96TB4K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40581d6",
      "metadata": {
        "hidden": true,
        "id": "d40581d6"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "seq_len_source = 10           # Length of each source sequence.\n",
        "seq_len_target = 10           # Length of each target sequence.\n",
        "batch_size = 2                # Number of samples in each batch.\n",
        "input_vocab_size = 50         # Vocabulary size for source language.\n",
        "target_vocab_size = 50        # Vocabulary size for target language.\n",
        "\n",
        "# Generate random source and target sequences as input data.\n",
        "source = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))\n",
        "target = torch.randint(1, target_vocab_size, (batch_size, seq_len_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To initialize the Transformer model, we define key hyperparameters that control the model's structure and complexity:\n",
        "\n",
        "- **d_model**: Dimensionality of the model and embedding size (e.g., 512), which determines the size of each token’s representation.\n",
        "- **num_heads**: Number of attention heads in multi-head attention (e.g., 8), allowing the model to focus on different parts of the input sequence in parallel.\n",
        "- **d_ff**: Dimensionality of the feedforward layer (e.g., 2048), enabling the model to learn complex transformations on token representations.\n",
        "- **num_layers**: Number of layers in both the encoder and decoder (e.g., 6), which defines the depth of the model and increases its representational capacity.\n",
        "\n",
        "Model Instantiation\n",
        "- **Transformer Model**: Using the specified hyperparameters, the `Transformer` model is instantiated, defining the encoder-decoder structure for processing source and target sequences.\n",
        "- **Device Assignment**: The model and input tensors (`source` and `target`) are moved to the specified device (GPU or CPU) for efficient computation.\n",
        "\n",
        "With these hyperparameters and setup, the model is ready for a forward pass with the defined test sequences, enabling us to test the end-to-end functionality of the Transformer."
      ],
      "metadata": {
        "id": "MslK8qwnTLVa"
      },
      "id": "MslK8qwnTLVa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7cf689",
      "metadata": {
        "hidden": true,
        "id": "fc7cf689"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters for the Transformer Model\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "d_ff = 2048\n",
        "num_layers = 6\n",
        "\n",
        "# Instantiate the Transformer model with the specified parameters.\n",
        "model = Transformer(d_model, num_heads, d_ff, num_layers, input_vocab_size, target_vocab_size, max_len=MAX_SEQ_LEN, dropout=0.1)\n",
        "\n",
        "# Move the model and input tensors to the specified device (GPU or CPU).\n",
        "model = model.to(device)\n",
        "source = source.to(device)\n",
        "target = target.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After setting up the model and test data, we perform a forward pass through the Transformer to obtain predictions for the target sequence.\n",
        "\n",
        "- **Forward Pass**:\n",
        "  - `output = model(source, target)`: Feeds the `source` and `target` sequences into the model, generating a predicted output tensor.\n",
        "  - The expected shape of the output tensor is `[batch_size, seq_len_target, target_vocab_size]`. In this test case, the expected shape would be `[2, 10, 50]`, where:\n",
        "    - `2` represents the batch size,\n",
        "    - `10` is the target sequence length, and\n",
        "    - `50` is the size of the target vocabulary.\n",
        "\n",
        "- **Output Shape Verification**:\n",
        "  - `print(f'output.shape {output.shape}')`: Prints the shape of the output tensor, allowing us to confirm that the model produces predictions with the expected dimensions.\n",
        "\n",
        "This test verifies that the model is processing the input data correctly and that its output aligns with the expected structure for translation tasks."
      ],
      "metadata": {
        "id": "kwJ9ojhVTQDJ"
      },
      "id": "kwJ9ojhVTQDJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4618560e",
      "metadata": {
        "hidden": true,
        "id": "4618560e"
      },
      "outputs": [],
      "source": [
        "# Perform a forward pass through the model with source and target sequences.\n",
        "output = model(source, target)  # Get the model's output for the given input sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab0bc69d",
      "metadata": {
        "hidden": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab0bc69d",
        "outputId": "66e218e0-92d6-4f93-c6c3-e8f3d274b4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ouput.shape torch.Size([2, 10, 50])\n"
          ]
        }
      ],
      "source": [
        "# Expected output shape -> [batch, seq_len_target, target_vocab_size] i.e. [2, 10, 50]\n",
        "\n",
        "# Print the shape of the output tensor to verify dimensions.\n",
        "print(f'ouput.shape {output.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4b2910",
      "metadata": {
        "id": "0f4b2910"
      },
      "source": [
        "## **Translator Eng-Spa**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a translation model, we load a dataset of English-Spanish sentence pairs from a text file.\n",
        "\n",
        "Key Steps\n",
        "- **File Path**:\n",
        "  - `PATH` specifies the location of the text file containing English-Spanish pairs, with each line containing one pair separated by a tab (`\\t`).\n",
        "\n",
        "- **Reading the File**:\n",
        "  - `with open(PATH, 'r', encoding='utf-8') as f`: Opens the file with UTF-8 encoding to handle special characters.\n",
        "  - `lines = f.readlines()`: Reads all lines from the file.\n",
        "\n",
        "- **Splitting into Pairs**:\n",
        "  - `eng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]`: Processes each line to create a list of English-Spanish pairs by splitting on the tab separator. Lines without a tab are ignored.\n",
        "\n",
        "- **Extracting Sentences**:\n",
        "  - `eng_sentences` and `spa_sentences` are lists containing only the English and Spanish sentences, respectively, extracted from `eng_spa_pairs`.\n",
        "\n",
        "- **Preview of Data**:\n",
        "  - Display the first 10 pairs to verify that the data has been loaded correctly.\n",
        "\n",
        "This setup provides a list of English and Spanish sentences, ready for tokenization and further preprocessing in the translation model."
      ],
      "metadata": {
        "id": "ZoowqFP4Tzf5"
      },
      "id": "ZoowqFP4Tzf5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "869a7244",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869a7244",
        "outputId": "27b1690e-8c47-47f5-86c5-8798de26c237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ow!', 'So?', 'Go.', 'Hi.', 'OK.', 'Go!', 'Ah!', 'Go.', 'Go!', 'OK.']\n",
            "['Â¡Ay!', 'Â¿Y?', 'Ve.', 'Hola.', 'Â¡Ã\\x93rale!', 'Vete', 'Â¡Anda!', 'VÃ¡yase.', 'VÃ¡yase', 'Bueno.']\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the text file containing English-Spanish sentence pairs.\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/eng-spa2024.csv'\n",
        "\n",
        "# Open the file and read all lines with UTF-8 encoding.\n",
        "with open(PATH, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Split each line into English-Spanish pairs, ignoring lines without a tab separator.\n",
        "eng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]\n",
        "\n",
        "# Display the first 10 English-Spanish pairs.\n",
        "eng_spa_pairs[:10]\n",
        "\n",
        "# Extract the English sentences from the pairs.\n",
        "eng_sentences = [pair[0] for pair in eng_spa_pairs]\n",
        "\n",
        "# Extract the Spanish sentences from the pairs.\n",
        "spa_sentences = [pair[1] for pair in eng_spa_pairs]\n",
        "\n",
        "# Print the first 10 English and Spanish sentences.\n",
        "print(eng_sentences[:10])\n",
        "print(spa_sentences[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Preprocess Sentences**"
      ],
      "metadata": {
        "id": "TiT-ZiI0wRQF"
      },
      "id": "TiT-ZiI0wRQF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Preprocessing\n",
        "\n",
        "The `preprocess_sentence` function prepares text data by cleaning and normalizing sentences. This process ensures that the input text is consistent and formatted for the model.\n",
        "\n",
        "Key Steps in Sentence Preprocessing\n",
        "- **Standardize Text**: Converts text to lowercase, removes extra whitespace, and normalizes accented characters.\n",
        "- **Remove Unnecessary Characters**: Filters out non-alphabetic characters, keeping only relevant text for translation.\n",
        "- **Add Special Tokens**: Adds `<sos>` and `<eos>` tokens to mark the start and end of each sentence, providing clear boundaries for the model.\n",
        "\n",
        "This preprocessing function ensures that sentences are in a clean, consistent format, ready for model input."
      ],
      "metadata": {
        "id": "3l85oB6BUttJ"
      },
      "id": "3l85oB6BUttJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d11478",
      "metadata": {
        "id": "60d11478"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "\n",
        "    # Convert sentence to lowercase and remove leading/trailing whitespace.\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    # Replace multiple spaces with a single space.\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "    # Normalize accented characters to their non-accented equivalents.\n",
        "    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n",
        "    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n",
        "    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n",
        "    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n",
        "    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n",
        "\n",
        "    # Remove non-alphabetic characters.\n",
        "    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n",
        "\n",
        "    # Remove leading/trailing spaces after cleaning.\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    # Add start and end tokens to sentence.\n",
        "    sentence = '<sos> ' + sentence + ' <eos>'\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "478f673b",
      "metadata": {
        "id": "478f673b"
      },
      "outputs": [],
      "source": [
        "s1 = '¿Hola @ cómo estás? 123'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ac79c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96ac79c5",
        "outputId": "954abb72-fd35-4b38-f361-e0ef720de65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Hola @ cómo estás? 123\n",
            "<sos> hola como estas <eos>\n"
          ]
        }
      ],
      "source": [
        "print(s1)\n",
        "print(preprocess_sentence(s1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9fc9c4d",
      "metadata": {
        "id": "d9fc9c4d"
      },
      "outputs": [],
      "source": [
        "eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\n",
        "spa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a3b18d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7a3b18d",
        "outputId": "91acc488-08a1-4810-caab-071370472ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> ay <eos>',\n",
              " '<sos> y <eos>',\n",
              " '<sos> ve <eos>',\n",
              " '<sos> hola <eos>',\n",
              " '<sos> rale <eos>',\n",
              " '<sos> vete <eos>',\n",
              " '<sos> anda <eos>',\n",
              " '<sos> v yase <eos>',\n",
              " '<sos> v yase <eos>',\n",
              " '<sos> bueno <eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "spa_sentences[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Build Vocabulary**"
      ],
      "metadata": {
        "id": "qaQCYG47wtvV"
      },
      "id": "qaQCYG47wtvV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `build_vocab` function creates a vocabulary from a list of sentences, mapping each unique word to a corresponding index.\n",
        "\n",
        "Key Steps in Building Vocabulary\n",
        "- **Tokenize and Count Words**: Splits sentences into words and counts the frequency of each word.\n",
        "- **Sort by Frequency**: Orders words by their frequency in descending order, allowing the most common words to have the lowest indices.\n",
        "- **Create Word-to-Index Mapping**: Assigns a unique index to each word, starting from index 2. Special tokens are added for padding (`<pad>`) and unknown words (`<unk>`) at indices 0 and 1, respectively.\n",
        "- **Create Index-to-Word Mapping**: Reverses the word-to-index mapping, enabling conversion back from indices to words.\n",
        "\n",
        "This function generates vocabulary dictionaries that facilitate the conversion between text and numeric indices, essential for processing input data for the model."
      ],
      "metadata": {
        "id": "9B_F_REKKTzS"
      },
      "id": "9B_F_REKKTzS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97931cd3",
      "metadata": {
        "id": "97931cd3"
      },
      "outputs": [],
      "source": [
        "def build_vocab(sentences):\n",
        "\n",
        "    # Flatten the list of sentences into individual words.\n",
        "    words = [word for sentence in sentences for word in sentence.split()]\n",
        "\n",
        "    # Count the occurrences of each word.\n",
        "    word_count = Counter(words)\n",
        "\n",
        "    # Sort words by frequency in descending order.\n",
        "    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "    # Create a mapping of words to indices starting from index 2.\n",
        "    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n",
        "\n",
        "    # Add special tokens for padding and unknown words.\n",
        "    word2idx['<pad>'] = 0\n",
        "    word2idx['<unk>'] = 1\n",
        "\n",
        "    # Reverse the mapping: indices to words.\n",
        "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "    return word2idx, idx2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa8738e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fa8738e",
        "outputId": "77bad329-e2bf-4710-c789-7b40ca625f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27672 43296\n"
          ]
        }
      ],
      "source": [
        "# Build vocabulary for English and Spanish sentences.\n",
        "eng_word2idx, eng_idx2word = build_vocab(eng_sentences)\n",
        "spa_word2idx, spa_idx2word = build_vocab(spa_sentences)\n",
        "\n",
        "# Get the vocabulary sizes for both languages.\n",
        "eng_vocab_size = len(eng_word2idx)\n",
        "spa_vocab_size = len(spa_word2idx)\n",
        "\n",
        "# Print the vocabulary sizes.\n",
        "print(eng_vocab_size, spa_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**English-Spanish Dataset**"
      ],
      "metadata": {
        "id": "Z9uQgCxIxU1O"
      },
      "id": "Z9uQgCxIxU1O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `EngSpaDataset` class defines a custom dataset for loading English-Spanish sentence pairs, preparing them for use in the translation model.\n",
        "\n",
        "Key Components of the EngSpaDataset Class\n",
        "- **Initialization**:\n",
        "  - Accepts lists of English and Spanish sentences along with vocabulary mappings for each language. These mappings (`eng_word2idx` and `spa_word2idx`) are used to convert words into index representations.\n",
        "\n",
        "- **Dataset Length**:\n",
        "  - The `__len__` method returns the number of sentence pairs in the dataset, which is the total number of training examples.\n",
        "\n",
        "- **Get Item**:\n",
        "  - The `__getitem__` method retrieves a sentence pair (English and Spanish) by index.\n",
        "  - Each sentence is tokenized by converting words to their respective indices using the vocabulary dictionaries, with unknown words replaced by the `<unk>` token.\n",
        "  - The method returns the tokenized English and Spanish sentences as tensors.\n",
        "\n",
        "This dataset class enables efficient loading and tokenization of English-Spanish sentence pairs, readying them for model training."
      ],
      "metadata": {
        "id": "YckfPiJlKiEF"
      },
      "id": "YckfPiJlKiEF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e564017c",
      "metadata": {
        "id": "e564017c"
      },
      "outputs": [],
      "source": [
        "# Define a custom Dataset for English-Spanish sentence pairs.\n",
        "class EngSpaDataset(Dataset):\n",
        "\n",
        "    # Initialize dataset with English and Spanish sentences and vocab mappings.\n",
        "    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n",
        "\n",
        "        self.eng_sentences = eng_sentences  # List of English sentences.\n",
        "        self.spa_sentences = spa_sentences  # List of Spanish sentences.\n",
        "\n",
        "        self.eng_word2idx = eng_word2idx  # English word-to-index dictionary.\n",
        "        self.spa_word2idx = spa_word2idx  # Spanish word-to-index dictionary.\n",
        "\n",
        "    # Return the number of sentences in the dataset.\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.eng_sentences)\n",
        "\n",
        "    # Return the tokenized index version of an English-Spanish sentence pair.\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        eng_sentence = self.eng_sentences[idx]  # Get the English sentence at the given index.\n",
        "        spa_sentence = self.spa_sentences[idx]  # Get the Spanish sentence at the given index.\n",
        "\n",
        "        # Convert English and Spanish sentences to indices using respective vocabularies.\n",
        "        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n",
        "        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n",
        "\n",
        "        # Return the tokenized English and Spanish sentences as tensors.\n",
        "        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b579577b",
      "metadata": {
        "id": "b579577b"
      },
      "outputs": [],
      "source": [
        "# Custom collate function to process a batch of sentences for the DataLoader.\n",
        "def collate_fn(batch):\n",
        "\n",
        "    # Unzip the batch into English and Spanish sentence pairs.\n",
        "    eng_batch, spa_batch = zip(*batch)\n",
        "\n",
        "    # Truncate or pad English sentences to a maximum sequence length (MAX_SEQ_LEN).\n",
        "    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n",
        "\n",
        "    # Truncate or pad Spanish sentences to a maximum sequence length (MAX_SEQ_LEN).\n",
        "    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n",
        "\n",
        "    # Pad the English sentences to ensure all sequences in the batch are of equal length.\n",
        "    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Pad the Spanish sentences to ensure all sequences in the batch are of equal length.\n",
        "    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Return the padded English and Spanish sentence batches.\n",
        "    return eng_batch, spa_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Training**"
      ],
      "metadata": {
        "id": "XrZLMRg8xhld"
      },
      "id": "XrZLMRg8xhld"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `train` function defines the training loop for the Transformer model, iteratively adjusting the model’s parameters to minimize the loss between predicted and target translations.\n",
        "\n",
        "Key Steps in the Training Loop\n",
        "- **Model Training Mode**:\n",
        "  - `model.train()` sets the model to training mode, enabling dropout layers and other training-specific behavior.\n",
        "\n",
        "- **Epoch Loop**:\n",
        "  - For each epoch, the model processes all batches in the dataloader. The total loss for the epoch is tracked to monitor training progress.\n",
        "\n",
        "- **Batch Processing**:\n",
        "  - Each batch of English and Spanish sentences is loaded and moved to the specified device (GPU or CPU).\n",
        "  - The target (Spanish) batch is split into `target_input` (input for the decoder) and `target_output` (correct output for loss calculation). The last token is removed from `target_input`, and the first token is removed from `target_output` to align them for prediction.\n",
        "\n",
        "- **Forward Pass and Loss Calculation**:\n",
        "  - The model generates predictions from the `eng_batch` and `target_input`.\n",
        "  - The output is reshaped to match the shape of `target_output`, and the loss is calculated between the model's predictions and the actual target output.\n",
        "\n",
        "- **Backpropagation and Optimization**:\n",
        "  - Gradients are reset, and the model performs backpropagation to calculate gradients of the loss with respect to model parameters.\n",
        "  - The optimizer updates the model's parameters to minimize the loss.\n",
        "\n",
        "- **Epoch Loss Tracking**:\n",
        "  - The average loss for the epoch is calculated and printed, allowing us to track the model's learning progress over time.\n",
        "\n",
        "This training loop optimizes the model’s parameters, gradually reducing the loss and improving the model's translation accuracy."
      ],
      "metadata": {
        "id": "pEslumohKsSC"
      },
      "id": "pEslumohKsSC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d514b7c",
      "metadata": {
        "id": "8d514b7c"
      },
      "outputs": [],
      "source": [
        "# Training loop for the Transformer model\n",
        "def train(model, dataloader, loss_function, optimiser, epochs):\n",
        "\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0  # Initialize total loss for the epoch\n",
        "\n",
        "        # Loop over batches in the dataloader\n",
        "        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n",
        "            # Move batches to the device (GPU or CPU)\n",
        "            eng_batch = eng_batch.to(device)\n",
        "            spa_batch = spa_batch.to(device)\n",
        "\n",
        "            # Preprocess target (Spanish) sentences for the decoder\n",
        "            target_input = spa_batch[:, :-1]\n",
        "            target_output = spa_batch[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            # Zero the gradients before backpropagation\n",
        "            optimiser.zero_grad()\n",
        "\n",
        "            # Run the model and get output\n",
        "            output = model(eng_batch, target_input)\n",
        "            output = output.view(-1, output.size(-1))\n",
        "\n",
        "            # Compute loss between model output and target output\n",
        "            loss = loss_function(output, target_output)\n",
        "\n",
        "            # Backpropagation and parameter update\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "\n",
        "            # Accumulate loss for the current batch\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "        # Print progress at the end of the epoch\n",
        "        print(f'Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2379ea72",
      "metadata": {
        "id": "2379ea72"
      },
      "outputs": [],
      "source": [
        "# Define batch size for training.\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Initialize the dataset for English-Spanish sentence pairs.\n",
        "dataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx)\n",
        "\n",
        "# Create a DataLoader for batching, shuffling, and padding sequences.\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08eef6a",
      "metadata": {
        "id": "e08eef6a"
      },
      "outputs": [],
      "source": [
        "# Initialize the Transformer model with specified hyperparameters.\n",
        "model = Transformer(\n",
        "    d_model=512,\n",
        "    num_heads=8,\n",
        "    d_ff=2048,\n",
        "    num_layers=6,\n",
        "    input_vocab_size=eng_vocab_size,  # Vocabulary size for input (English).\n",
        "    target_vocab_size=spa_vocab_size, # Vocabulary size for output (Spanish).\n",
        "    max_len=MAX_SEQ_LEN,              # Maximum sequence length.\n",
        "    dropout=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1181a12",
      "metadata": {
        "id": "a1181a12"
      },
      "outputs": [],
      "source": [
        "# Move the model to the specified device (GPU/CPU).\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function as CrossEntropyLoss, ignoring padding index (0).\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "# Set up the Adam optimizer with a learning rate of 0.0001 for model parameters.\n",
        "optimiser = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e265e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14e265e9",
        "outputId": "62aa98bf-c485-4fdd-bc93-983fd0aa8d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/10, Loss: 3.4942\n",
            "Epoch: 1/10, Loss: 2.1202\n",
            "Epoch: 2/10, Loss: 1.6389\n",
            "Epoch: 3/10, Loss: 1.3261\n",
            "Epoch: 4/10, Loss: 1.0884\n",
            "Epoch: 5/10, Loss: 0.8961\n",
            "Epoch: 6/10, Loss: 0.7403\n",
            "Epoch: 7/10, Loss: 0.6183\n",
            "Epoch: 8/10, Loss: 0.5259\n",
            "Epoch: 9/10, Loss: 0.4601\n"
          ]
        }
      ],
      "source": [
        "# Train the model using the provided data loader, loss function, optimizer, and number of epochs (10).\n",
        "train(model, dataloader, loss_function, optimiser, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Translate Sentences**"
      ],
      "metadata": {
        "id": "gZHUas2DzrmX"
      },
      "id": "gZHUas2DzrmX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `sentence_to_indices` and `indices_to_sentence` functions handle conversions between sentences and their indexed representations, which is essential for processing text in the model.\n",
        "\n",
        "`sentence_to_indices`\n",
        "- **Purpose**: Converts a sentence (string) into a list of word indices based on a word-to-index (`word2idx`) mapping.\n",
        "- **Functionality**: Each word in the sentence is replaced by its corresponding index. If a word is not in the vocabulary, it is replaced by the index for the `<unk>` (unknown) token.\n",
        "\n",
        "`indices_to_sentence`\n",
        "- **Purpose**: Converts a list of indices back into a readable sentence using an index-to-word (`idx2word`) mapping.\n",
        "- **Functionality**: Each index is replaced by its corresponding word. Padding tokens (`<pad>`) are excluded to avoid unnecessary spaces in the reconstructed sentence.\n",
        "\n",
        "These functions facilitate the conversion between text and numeric representations, making it possible to input text data to the model and convert model predictions back to human-readable text."
      ],
      "metadata": {
        "id": "l7ZUtAXfK62a"
      },
      "id": "l7ZUtAXfK62a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert a sentence into a list of word indices using the provided word-to-index mapping.\n",
        "def sentence_to_indices(sentence, word2idx):\n",
        "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
        "\n",
        "# Convert a list of indices back into a sentence using the provided index-to-word mapping.\n",
        "def indices_to_sentence(indices, idx2word):\n",
        "    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])"
      ],
      "metadata": {
        "id": "Wshl54Wr0aBH"
      },
      "id": "Wshl54Wr0aBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `translate_sentence` function uses a trained Transformer model to translate an input sentence from English to Spanish by encoding the input and generating a target sequence token-by-token.\n",
        "\n",
        "Key Steps in Translation\n",
        "- **Model Evaluation Mode**:\n",
        "  - `model.eval()` sets the model to evaluation mode, which disables dropout layers and ensures consistent inference behavior.\n",
        "\n",
        "- **Sentence Preprocessing**:\n",
        "  - The input sentence is preprocessed to match the format expected by the model (e.g., lowercase, removing extra spaces, adding special tokens).\n",
        "\n",
        "- **Convert Sentence to Indices**:\n",
        "  - `sentence_to_indices` is used to map the words in the preprocessed sentence to their corresponding indices based on the English vocabulary.\n",
        "  - This indexed sentence is then converted to a tensor and moved to the appropriate device (CPU or GPU).\n",
        "\n",
        "- **Initialize Target Sequence**:\n",
        "  - The target sequence begins with the `<sos>` (start-of-sequence) token. This token acts as a starting point for the model to begin generating the translation.\n",
        "\n",
        "- **Token Generation Loop**:\n",
        "  - The function generates each token in the target sentence iteratively:\n",
        "    - The model's output is computed based on the input tensor and the current state of the target sequence.\n",
        "    - The most probable next token is determined by selecting the index with the highest probability.\n",
        "    - This token is added to the target sequence, and the process continues until either the maximum length is reached or the `<eos>` (end-of-sequence) token is generated.\n",
        "\n",
        "- **Convert Indices to Sentence**:\n",
        "  - Once the target indices are generated, `indices_to_sentence` converts them back to a readable Spanish sentence.\n",
        "\n",
        "This function allows for sentence-by-sentence translation using a trained Transformer model, outputting the generated translation based on the model’s learned representations."
      ],
      "metadata": {
        "id": "SX8IyK_8LHAn"
      },
      "id": "SX8IyK_8LHAn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50740746",
      "metadata": {
        "code_folding": [],
        "id": "50740746"
      },
      "outputs": [],
      "source": [
        "# Translate a sentence using the trained model by encoding the input and generating a target sequence.\n",
        "def translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
        "    model.eval()  # Set the model to evaluation mode.\n",
        "    sentence = preprocess_sentence(sentence)  # Preprocess the input sentence.\n",
        "    input_indices = sentence_to_indices(sentence, eng_word2idx)  # Convert the sentence to indices.\n",
        "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)  # Convert indices to tensor.\n",
        "\n",
        "    # Initialize the target sequence with the <sos> token.\n",
        "    tgt_indices = [spa_word2idx['<sos>']]\n",
        "    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation during inference.\n",
        "        for _ in range(max_len):  # Generate tokens until max length or <eos> is reached.\n",
        "            output = model(input_tensor, tgt_tensor)  # Get model's output.\n",
        "            output = output.squeeze(0)\n",
        "            next_token = output.argmax(dim=-1)[-1].item()  # Get the most probable token.\n",
        "            tgt_indices.append(next_token)  # Append the token to the target sequence.\n",
        "            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)  # Update target tensor.\n",
        "            if next_token == spa_word2idx['<eos>']:  # Stop if <eos> token is generated.\n",
        "                break\n",
        "\n",
        "    return indices_to_sentence(tgt_indices, spa_idx2word)  # Convert generated indices back to a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Evaluate Translations**"
      ],
      "metadata": {
        "id": "x14sYJLl0lCR"
      },
      "id": "x14sYJLl0lCR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `evaluate_translations` function takes a list of English sentences, translates each using the trained Transformer model, and displays the original sentences alongside their translations.\n",
        "\n",
        "Key Steps in Translation Evaluation\n",
        "- **Iterate Through Sentences**:\n",
        "  - For each sentence in the provided list, the function generates a Spanish translation by calling `translate_sentence`, which leverages the model to predict the target sequence.\n",
        "\n",
        "- **Display Results**:\n",
        "  - The original input sentence and its corresponding translation are printed side-by-side for easy comparison.\n",
        "\n",
        "This function provides an efficient way to evaluate the model’s translation performance on multiple sentences, allowing for quick inspection of translation quality."
      ],
      "metadata": {
        "id": "eLmaBKUmLO63"
      },
      "id": "eLmaBKUmLO63"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the translations of a list of sentences using the trained model.\n",
        "def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
        "\n",
        "    # Iterate through each sentence in the provided list.\n",
        "    for sentence in sentences:\n",
        "        # Translate the sentence using the trained model.\n",
        "        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n",
        "\n",
        "        # Print the original sentence and its translation.\n",
        "        print(f'Input Sentence: {sentence}')\n",
        "        print(f'Translation: {translation}')\n",
        "        print()"
      ],
      "metadata": {
        "id": "-NtgD8O-0s5B"
      },
      "id": "-NtgD8O-0s5B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c0db72",
      "metadata": {
        "code_folding": [
          15
        ],
        "id": "c2c0db72"
      },
      "outputs": [],
      "source": [
        "# Sentences to test the translator.\n",
        "test_sentences = [\n",
        "\n",
        "    \"What time is it right now?\",\n",
        "    \"I need to buy groceries today.\",\n",
        "    \"The stars look beautiful tonight.\",\n",
        "    \"Can you show me how to do this?\",\n",
        "    \"This movie is really entertaining.\",\n",
        "    \"I enjoy listening to music in my free time.\",\n",
        "    \"The water in the lake is so clear.\",\n",
        "    \"Let’s take a walk in the park.\",\n",
        "    \"He hide himself in the citchen\",\n",
        "    \"She asked for a candy\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available and set the device accordingly.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device (GPU/CPU).\n",
        "model = model.to(device)\n",
        "\n",
        "# Evaluate the translations for the test sentences.\n",
        "evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukDdhFIn1ciV",
        "outputId": "c63fc28d-db06-4d7b-f074-d0223c9f4f17"
      },
      "id": "ukDdhFIn1ciV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence: What time is it right now?\n",
            "Translation: <sos> ahora mismo es lo que es <eos>\n",
            "\n",
            "Input Sentence: I need to buy groceries today.\n",
            "Translation: <sos> tengo que comprar hoy <eos>\n",
            "\n",
            "Input Sentence: The stars look beautiful tonight.\n",
            "Translation: <sos> las estrellas se ven hermosas esta noche <eos>\n",
            "\n",
            "Input Sentence: Can you show me how to do this?\n",
            "Translation: <sos> puedes mostrarme c mo hacer esto <eos>\n",
            "\n",
            "Input Sentence: This movie is really entertaining.\n",
            "Translation: <sos> esta pel cula es muy entretenida <eos>\n",
            "\n",
            "Input Sentence: I enjoy listening to music in my free time.\n",
            "Translation: <sos> me gusta escuchar m sica en mi tiempo libre <eos>\n",
            "\n",
            "Input Sentence: The water in the lake is so clear.\n",
            "Translation: <sos> el lago est tan clara en el agua <eos>\n",
            "\n",
            "Input Sentence: Let’s take a walk in the park.\n",
            "Translation: <sos> demos un paseo en el parque <eos>\n",
            "\n",
            "Input Sentence: He hide himself in the citchen\n",
            "Translation: <sos> l se oculta el dinero en el lugar <eos>\n",
            "\n",
            "Input Sentence: She asked for a candy\n",
            "Translation: <sos> ella pidi un dulce <eos>\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}